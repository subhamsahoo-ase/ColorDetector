{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8371377",
   "metadata": {},
   "source": [
    "# Color Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "297a59f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2\n",
    "\n",
    "def get_limits(color):\n",
    "    \n",
    "    c = np.uint8([[color]]) # bgr values which you want to convert to hsv\n",
    "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "\n",
    "    lowerLimit = hsvC[0][0][0] - 10, 100, 100\n",
    "    upperLimit = hsvC[0][0][0] + 10, 255, 255\n",
    "    \n",
    "    lowerLimit = np.array(lowerLimit, dtype = np.uint8)\n",
    "    upperLimit = np.array(upperLimit, dtype = np.uint8)\n",
    "    \n",
    "    return lowerLimit, upperLimit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896bac86",
   "metadata": {},
   "source": [
    "## Color Detection using Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9f6ee29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "yellow = [0 ,255, 255] # yellow in bgr color space\n",
    "blue = [255, 0, 0]\n",
    "\n",
    "# open webcam\n",
    "while True:\n",
    "    ret, frame = cap.read() # reads the image from webcam\n",
    "    \n",
    "    # color detection stuff happens has to happen before the image is shown\n",
    "    \n",
    "    # first convert imaage from bgr to hsv color space\n",
    "    img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # use get_color function to return lower and upper limit in hsv cs for inRange function \n",
    "    lowerLimit, upperLimit = get_limits(blue)\n",
    "    \n",
    "    # generates a mask(T/F array) of all the pixel values that contain that color\n",
    "    mask = cv2.inRange(img_hsv, lowerLimit, upperLimit) # cv2.inRange(source, lower_limit, upper_limit)\n",
    "    \n",
    "    # converts the nmpy opencv represntation to a pillow object\n",
    "    mask_ = Image.fromarray(mask) \n",
    "    bbox = mask_.getbbox() # pillow has a function called getbbox that automatically get the bounding box for a set of pixels\n",
    "    \n",
    "    # prints location of bounding box of each yellow pixel\n",
    "    # print(bbox) \n",
    "    \n",
    "    if bbox is not None:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0))\n",
    "    \n",
    "    cv2.imshow('webcam', mask) # shows image on a new frame, to see mask, change frame to mask\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3698602f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 20,  20,  18, ..., 130, 173, 186],\n",
       "       [ 20,  20,  19, ..., 144, 126, 152],\n",
       "       [ 20,  20,  19, ..., 137, 136, 125],\n",
       "       ...,\n",
       "       [  6,   8,  10, ...,  80,  77,  79],\n",
       "       [  9,  11,  11, ...,  78,  75,  75],\n",
       "       [ 12,  14,  13, ...,  76,  75,  75]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_hsv[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c401a",
   "metadata": {},
   "source": [
    "HSV color space works like a cylinder. We want to define a margin of error between each h s and v value so that the program can pick up an oobject of a general color."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db538f40",
   "metadata": {},
   "source": [
    "## Color Detection using Saturation thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b593e505",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "yellow = [0 ,255, 255] # yellow in bgr color space\n",
    "blue = [255, 0, 0]\n",
    "\n",
    "# open webcam\n",
    "while True:\n",
    "    ret, frame = cap.read() # reads the image from webcam\n",
    "    \n",
    "    # color detection stuff happens has to happen before the image is shown\n",
    "    \n",
    "    # first convert imaage from bgr to hsv color space\n",
    "    img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # use get_color function to return lower and upper limit in hsv cs for inRange function \n",
    "    lowerLimit, upperLimit = get_limits(yellow)\n",
    "    \n",
    "    # generates a mask(T/F array) of all the pixel values that contain that color\n",
    "    mask = cv2.inRange(img_hsv, lowerLimit, upperLimit) # cv2.inRange(source, lower_limit, upper_limit)\n",
    "    \n",
    "    # Apply saturation thresholding \n",
    "    sat_thresh = 40 # adjust this value based on your environment\n",
    "    _, sat_mask = cv2.threshold(img_hsv[:,:,1], 170, 255, cv2.THRESH_BINARY) # img_hsv[:, :, 1] is the satruation channel of the img_hsv tensor\n",
    "    # adjust second parameter of threshold based on enrionment, or replace with sat_thresh and change that variable \n",
    "    \n",
    "    mask = cv2.bitwise_and(mask, sat_mask)\n",
    "    \n",
    "    \n",
    "    # converts the nmpy opencv represntation to a pillow object\n",
    "    mask_ = Image.fromarray(mask) \n",
    "    bbox = mask_.getbbox() # pillow has a function called getbbox that automatically get the bounding box for a set of pixels\n",
    "    \n",
    "    # prints location of bounding box of each yellow pixel\n",
    "    # print(bbox) \n",
    "    \n",
    "    if bbox is not None:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        \n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 10)\n",
    "    \n",
    "    cv2.imshow('webcam', mask) # shows image on a new frame, to see mask, change frame to mask\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99d7c3a",
   "metadata": {},
   "source": [
    "### What is img_hsv[:, :, 1]?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e01e2",
   "metadata": {},
   "source": [
    "In OpenCV, the HSV color space consists of three components: Hue, Saturation, and Value. The `img_hsv[:, :, 1]` refers to the Saturation channel of the image in HSV color space.\n",
    "\n",
    "Here's a breakdown of what each channel represents:\n",
    "\n",
    "- Hue (img_hsv[:, :, 0]): It represents the color itself, and it ranges from 0 to 179 in OpenCV.\n",
    "- Saturation (img_hsv[:, :, 1]): It represents the intensity of the color. A value of 0 means grayscale (no color), and a value of 255 means fully saturated color.\n",
    "- Value (img_hsv[:, :, 2]): It represents the brightness of the color. A higher value means brighter pixels.\n",
    "\n",
    "In the code you provided, `img_hsv[:, :, 1]` is extracting the Saturation channel of the image. This channel is then thresholded using the `cv2.threshold` function to create a binary mask (`sat_mask`). Pixels with saturation values below the specified threshold (`sat_thresh`) will be set to 0 (black) in the mask, and others will be set to 255 (white). This helps filter out pixels with low saturation, which might be caused by excessive light in the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9243a111",
   "metadata": {},
   "source": [
    "## Using Countours to find multiple objects of same color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54dc3a04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "yellow = [0 ,255, 255] # yellow in bgr color space\n",
    "blue = [255, 0, 0]\n",
    "\n",
    "# open webcam\n",
    "while True:\n",
    "    ret, frame = cap.read() # reads the image from webcam\n",
    "    \n",
    "    # color detection stuff happens has to happen before the image is shown\n",
    "    \n",
    "    # first convert imaage from bgr to hsv color space\n",
    "    img_hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    # use get_color function to return lower and upper limit in hsv cs for inRange function \n",
    "    lowerLimit, upperLimit = get_limits(yellow)\n",
    "    \n",
    "    # generates a mask(T/F array) of all the pixel values that contain that color\n",
    "    mask = cv2.inRange(img_hsv, lowerLimit, upperLimit) # cv2.inRange(source, lower_limit, upper_limit)\n",
    "    \n",
    "    # Apply saturation thresholding \n",
    "    sat_thresh = 180 # adjust this value based on your environment\n",
    "    _, sat_mask = cv2.threshold(img_hsv[:,:,1], sat_thresh, 255, cv2.THRESH_BINARY) # img_hsv[:, :, 1] is the satruation channel of the img_hsv tensor\n",
    "    # adjust second parameter of threshold based on enrionment, or replace with sat_thresh and change that variable \n",
    "    \n",
    "    mask = cv2.bitwise_and(mask, sat_mask)\n",
    "    \n",
    "    # find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    # Draw bounding boxes around each contour\n",
    "    \n",
    "    for cnt in contours:\n",
    "        \n",
    "        if cv2.contourArea(cnt) > 2000:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    \"\"\"\n",
    "    for cnt in contours:\n",
    "        print(cv2.contourArea(cnt))\n",
    "        if cv2.contourArea(cnt) > 0:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # converts the nmpy opencv represntation to a pillow object\n",
    "    mask_ = Image.fromarray(mask) \n",
    "    #bbox = mask_.getbbox() # pillow has a function called getbbox that automatically get the bounding box for a set of pixels\n",
    "    \n",
    "    # prints location of bounding box of each yellow pixel\n",
    "    # print(bbox) \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    if bbox is not None:\n",
    "        x1, y1, x2, y2 = bbox\n",
    "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 10)\n",
    "    \"\"\"\n",
    "    \n",
    "    cv2.imshow('webcam', frame) # shows image on a new frame, to see mask, change frame to mask\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ee5ef",
   "metadata": {},
   "source": [
    "In this modified code, after applying the color and saturation thresholds, we use the cv2.findContours function to detect contours in the binary mask. Then, for each contour, we compute its bounding box using cv2.boundingRect and draw a rectangle around it on the original frame. This allows you to detect and draw bounding boxes around multiple yellow objects separately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643affbf",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13367448",
   "metadata": {},
   "source": [
    "Because I was in the library, the lighting caued for a high saturation value. Saturation is the amount of gray that is in a color. Gray is effectively a mixture of black and white. So in cases where there is high lighitng, some colors will have more white(the parts of the image where lighting is well lit) and some parts of the image are more dark(absense of the light hitting it ie shadows). This is my understanding of it. I used 2 masks, one that extracts the color, and the other being a thresholding mask, where if saturation value is above 100 it goes to 255, and if it is below 100 it goes to 0. This sat mask effectively ignores spaces/colors have high lights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d300995",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
